# META Methods Checklist
# PURPOSE: Continuous governance of the risk assessment process itself
# LOAD: Throughout all phases, especially before OUTPUT

---
# META methods are applied CONTINUOUSLY, not just at the end
# Check after each phase for relevant META methods

application_schedule:
  after_identify:
    - 601  # Cognitive Bias Audit (optimism, availability, groupthink)
  after_quantify:
    - 601  # Cognitive Bias Audit (anchoring, confirmation)
    - 605  # Simpson's Paradox Audit
  after_mitigate:
    - 602  # Risk Appetite Calibration
  after_monitor:
    - 606  # Goodhart's Law Check
  before_output:
    - 601  # Final bias check
    - 602  # Appetite confirmation
    - 603  # Portfolio Risk View
    - 604  # Risk Communication Framework
    - 605  # Simpson's Paradox Audit
    - 606  # Goodhart's Law Check

---
methods:
  - id: 601
    name: "Cognitive Bias Audit"
    purpose: "Check the assessment itself for known biases"
    frequency: "After IDENTIFY, QUANTIFY, before OUTPUT"
    checklist:
      - bias: "OPTIMISM"
        sign: "All P scores < 3"
        question: "Are we underestimating probabilities?"
        countermeasure: "Use base rates (#204)"

      - bias: "ANCHORING"
        sign: "First estimates unchanged despite new info"
        question: "Are we stuck on initial assessments?"
        countermeasure: "Independent re-estimation"

      - bias: "AVAILABILITY"
        sign: "Recent/vivid events overweighted"
        question: "Are we overweighting memorable incidents?"
        countermeasure: "Systematic taxonomy (#101)"

      - bias: "GROUPTHINK"
        sign: "No dissenting scores, team convergence"
        question: "Is everyone agreeing too easily?"
        countermeasure: "Anonymous scoring, invite outsider"

      - bias: "NORMALCY"
        sign: '"It has always been fine"'
        question: "Are we assuming continuity?"
        countermeasure: "Historical pattern check (#106)"

      - bias: "OSTRICH"
        sign: "Uncomfortable risks missing"
        question: "Are we avoiding hard conversations?"
        countermeasure: "Blind spot interrogation (#109)"

      - bias: "SUNK_COST"
        sign: '"Too invested to stop"'
        question: "Are we protecting past decisions?"
        countermeasure: "Pre-committed thresholds"

      - bias: "DUNNING_KRUGER"
        sign: "Overconfident in weak areas"
        question: "Are we most confident where we know least?"
        countermeasure: "Explicit expertise gap mapping"

      - bias: "CONFIRMATION"
        sign: "Only supporting evidence considered"
        question: "Did we seek contrary evidence?"
        countermeasure: "Contraposition (#107), Devil's advocate"

  - id: 602
    name: "Risk Appetite Calibration"
    purpose: "Ensure stated vs revealed appetite alignment"
    frequency: "After MITIGATE, before OUTPUT"
    checklist:
      dimensions:
        - name: "FINANCIAL"
          stated_options: ["Conservative", "Moderate", "Aggressive"]
          check: "Do TOLERATE decisions match stated appetite?"

        - name: "TIMELINE"
          stated_options: ["Buffer everywhere", "Tight but achievable", "Ambitious"]
          check: "Are timeline risks treated consistently with appetite?"

        - name: "TECHNICAL"
          stated_options: ["Proven only", "Proven core + experimental edges", "Cutting edge"]
          check: "Is tech risk tolerance consistent?"

        - name: "REPUTATION"
          stated_options: ["Zero incidents", "Managed response", "Move fast apologize later"]
          check: "Are reputation risks treated per appetite?"

        - name: "REGULATORY"
          stated_options: ["Exceed requirements", "Meet requirements", "Minimum viable"]
          check: "Is compliance risk tolerance consistent?"

      red_flag: "Gap between stated and revealed appetite is itself a risk"

  - id: 603
    name: "Portfolio Risk View"
    purpose: "Aggregate individual risks into portfolio assessment"
    frequency: "Before OUTPUT"
    checklist:
      metrics:
        - name: "Total Expected Loss"
          threshold: "vs total budget/value"
          action: "If exceeds, reduce highest-impact risks"

        - name: "Max Simultaneous Loss"
          threshold: "vs survivability"
          action: "If exceeds, break correlations or add insurance"

        - name: "Risk Concentration"
          threshold: ">60% in top 3 risks = too concentrated"
          action: "Diversify mitigations"

        - name: "Mitigation Coverage"
          threshold: "<80% of CRITICAL/HIGH = gap"
          action: "Add mitigations or justify tolerance"

        - name: "Monitoring Coverage"
          threshold: "<70% = blind flying"
          action: "Add leading indicators"

        - name: "Non-Ergodic Count"
          threshold: "Any unmitigated = RED"
          action: "Must address existential risks"

        - name: "Fat-Tail Count"
          threshold: "Any unmitigated = RED"
          action: "Use P99 estimates, not expected value"

      key_question: "Is total portfolio acceptable even if individual risks are?"

  - id: 604
    name: "Risk Communication Framework"
    purpose: "Ensure right view for right audience"
    frequency: "During OUTPUT"
    checklist:
      audiences:
        - audience: "Engineering"
          needs: "Technical detail, actions"
          format: "Detailed register, tickets"
          level_of_detail: "Full"

        - audience: "PM/EM"
          needs: "Priority, timeline impact"
          format: "Top-10 dashboard"
          level_of_detail: "Summary + critical details"

        - audience: "Executives"
          needs: "Business impact, strategic implications"
          format: "Heat map, 3-bullet summary"
          level_of_detail: "Executive summary"

        - audience: "Client"
          needs: "Assurance, material risks"
          format: "Curated report"
          level_of_detail: "Appropriate disclosure"

        - audience: "Regulators"
          needs: "Compliance evidence"
          format: "Formal assessment"
          level_of_detail: "Per requirements"

  - id: 605
    name: "Simpson's Paradox Audit"
    purpose: "Check if aggregate hides dangerous subgroups"
    frequency: "After QUANTIFY, before OUTPUT"
    checklist:
      disaggregate_by:
        - "Client"
        - "Team"
        - "Component/Module"
        - "Geography/Region"
        - "Time period"

      check: |
        For each subgroup:
        1. Calculate subgroup aggregate metrics
        2. Compare to overall aggregate
        3. If aggregate=GREEN but any subgroup=RED → PARADOX
        4. Document hidden risk

      example: |
        Aggregate: "Average risk score 2.3" → Looks fine
        By component:
          - Core: 1.2 → Fine
          - Auth: 1.5 → Fine
          - Reporting: 4.8 → CRITICAL
        Simpson's Paradox: Aggregate hides that reporting module is in crisis

  - id: 606
    name: "Goodhart's Law Check"
    purpose: "Audit metrics for gaming/decay"
    frequency: "After MONITOR, before OUTPUT"
    checklist:
      warning_signs:
        - sign: "All metrics are green"
          meaning: "Either truly excellent OR being gamed"
          action: "Spot check, look for corroborating evidence"

        - sign: "Risk count never increases"
          meaning: "Either no new risks OR stopped identifying"
          action: "Check incentives for reporting"

        - sign: "All estimates are round numbers"
          meaning: "P=3, I=3 for everything = not actually estimating"
          action: "Require rationale for each score"

        - sign: "Reviews always take exact scheduled time"
          meaning: "Either perfectly calibrated OR rubber-stamped"
          action: "Sample deep-dive on random items"

        - sign: "No risks ever escalated"
          meaning: "Either nothing serious OR escalation is punished"
          action: "Check escalation incentives"

        - sign: "Mitigation completion is 100%"
          meaning: "Either excellent execution OR 'done' ≠ 'working'"
          action: "Verify effectiveness, not just completion"

      recommendations:
        - "Rotate metrics periodically"
        - "Check incentive alignment"
        - "Audit for proxy failure (metric ≠ actual goal)"
        - "Use multiple uncorrelated indicators"

---
# Quick META checklist for each phase
quick_checks:
  identify: "Am I missing risks due to bias? What am I not seeing?"
  quantify: "Are my scores anchored? Am I being too optimistic?"
  interact: "Am I treating correlated risks as independent?"
  mitigate: "Do my TOLERATE decisions match stated appetite?"
  monitor: "Can these metrics be gamed? Are incentives aligned?"
  output: "Does aggregate hide subgroup problems? Right format for audience?"
