# #22 Black Swan Hunt

**Tier:** 3 (Phase 3 - CHALLENGE)
**Purpose:** Search for low-probability high-impact events that could change everything.

## Core Principle

Black Swans (Nassim Taleb) are events that are:
- Rare (outside normal expectations)
- Extreme impact (change everything)
- Retrospectively predictable (obvious in hindsight)

Normal planning ignores black swans. This method actively hunts for them.

## What to do

1. For each option, brainstorm "what could change everything?"
2. Include both positive and negative black swans
3. Assess: probability × impact, but also survivability
4. Plan: monitoring, early warning, response options

## Output format

```
OPTION: [name]

NEGATIVE BLACK SWANS (could destroy this option):

BLACK SWAN: [event]
├── Probability: [Very Low / Low]
├── Impact if occurs: [Catastrophic / Severe]
├── Would we survive? [Yes / Maybe / No]
├── Early warning signs: [what to watch]
└── Hedge/Response: [what we could do]

POSITIVE BLACK SWANS (could make this option wildly successful):

BLACK SWAN: [event]
├── Probability: [Very Low / Low]
├── Impact if occurs: [Transformative]
├── Are we positioned to benefit? [Yes / No]
└── How to improve position: [action]

FRAGILITY ASSESSMENT:
• Most fragile to: [black swan]
• Most antifragile aspect: [what gets stronger under stress]
• Net fragility: [Fragile / Robust / Antifragile]
```

---

# #23 Assumption Stress Test

**Tier:** 3 (Phase 3 - CHALLENGE)
**Purpose:** Take each key assumption and imagine it's wrong.

## Core Principle

Every option rests on assumptions. Most failures come from wrong assumptions, not wrong logic.

"What if we're wrong about X?" is the most powerful question in planning.

## What to do

1. List all key assumptions underlying the option
2. For each assumption, imagine it's false
3. Ask: What breaks? How badly? Can we detect early?
4. Prioritize: Which wrong assumptions are most dangerous?

## Output format

```
OPTION: [name]

ASSUMPTION 1: [statement]
├── Confidence: [High/Med/Low] - based on [evidence]
├── If wrong: [what breaks]
├── Severity if wrong: [Fatal / Serious / Manageable]
├── How would we know it's wrong? [signal]
└── Backup plan: [alternative]

ASSUMPTION 2: [statement]
[repeat structure]

ASSUMPTION RISK MATRIX:
| Assumption | Confidence | If Wrong | Priority |
|------------|------------|----------|----------|
| [A1]       | [H/M/L]    | [impact] | [1-5]    |
| [A2]       | [H/M/L]    | [impact] | [1-5]    |

MOST DANGEROUS ASSUMPTIONS (Low confidence + High impact):
1. [assumption]: MUST validate before committing
2. [assumption]: MUST have backup plan
```

---

# #24 Regret Minimization

**Tier:** 3 (Phase 3 - CHALLENGE)
**Purpose:** Project forward and ask what you'd regret NOT considering.

## Core Principle

Jeff Bezos's Regret Minimization Framework: "When I'm 80, will I regret not trying this?"

Applied to exploration: "A year from now, what will I wish I had considered?"

This surfaces blind spots by invoking your future self's perspective.

## What to do

1. Imagine it's 1/5/10 years from now
2. The decision was made, things didn't go as planned
3. Ask: "What do I wish I had considered?"
4. Add those considerations to the exploration

## Output format

```
PROJECTION: It's [timeframe] from now.

SCENARIO A: We chose [option] and it FAILED.

Future self says:
"I wish I had considered..."
• [thing not yet explored]
• [thing not yet explored]
• [thing not yet explored]

"I wish I had asked..."
• [question not yet asked]
• [question not yet asked]

SCENARIO B: We chose [option] and it SUCCEEDED, but...

Future self says:
"Even though it worked, I wish I had..."
• [consideration]
• [consideration]

REGRET INVENTORY:
| Not considering X | Regret level | Should explore? |
|-------------------|--------------|-----------------|
| [item]            | [H/M/L]      | [Yes/No]        |

ADDITIONS TO EXPLORATION:
Based on regret minimization, we should add:
• [new dimension / option / question]
```

---

# #25 Devil's Advocate

**Tier:** 3 (Phase 3 - CHALLENGE)
**Purpose:** Argue passionately against the currently favored option.

## Core Principle

Confirmation bias makes us seek evidence for what we already believe. Devil's advocate forces the opposite: find the strongest case AGAINST the favored option.

The goal is not to change the decision, but to ensure it survives legitimate challenge.

## What to do

1. Identify the currently favored option
2. Adopt adversarial stance: "I must prove this is wrong"
3. Construct the strongest possible argument against it
4. Assess: Does the option survive? What weaknesses exposed?

## Output format

```
FAVORED OPTION: [option]
CURRENT CONFIDENCE: [%]

DEVIL'S ADVOCATE ARGUMENT:

"[Option] is a mistake because..."

ATTACK 1: [argument]
├── Evidence: [supporting points]
├── Strength: [Weak / Moderate / Strong / Devastating]
└── Counter: [defense if any]

ATTACK 2: [argument]
├── Evidence: [supporting points]
├── Strength: [Weak / Moderate / Strong / Devastating]
└── Counter: [defense if any]

ATTACK 3: [argument]
├── Evidence: [supporting points]
├── Strength: [Weak / Moderate / Strong / Devastating]
└── Counter: [defense if any]

SYNTHESIS:
• Strongest attack: [which one]
• Weakest defense: [where option is vulnerable]
• Overall: [Option survives / Option wounded / Option defeated]

CONFIDENCE AFTER CHALLENGE: [%]
Change: [+/- from before]
```

---

# #26 Red Team Options

**Tier:** 3 (Phase 3 - CHALLENGE)
**Purpose:** Imagine a competitor chose each option - how would they exploit it against you?

## Core Principle

Your decision exists in a competitive context. If you choose A, what does that enable competitors to do? How could they exploit your choice?

Think like an attacker targeting your strategy.

## What to do

1. For each major option, imagine a smart competitor
2. Ask: "How would they exploit this choice against us?"
3. Identify competitive vulnerabilities
4. Plan defensive measures

## Output format

```
IF WE CHOOSE: [Option A]

COMPETITOR EXPLOITATION SCENARIOS:

COMPETITOR: [type of competitor]
├── They would: [action they'd take]
├── Because our choice: [creates this vulnerability]
├── Impact on us: [what we lose]
└── Defense: [how we could counter]

COMPETITOR: [another competitor type]
├── They would: [action]
├── Because: [vulnerability]
├── Impact: [damage]
└── Defense: [counter]

VULNERABILITY SUMMARY:
| Option | Main Vulnerability | Worst Competitor Move | Defense |
|--------|--------------------|-----------------------|---------|
| A      | [vulnerability]    | [attack]              | [defense]|
| B      | [vulnerability]    | [attack]              | [defense]|

COMPETITIVE ROBUSTNESS: [High / Medium / Low]

Most defensible option: [which one]
Reason: [why]
```
