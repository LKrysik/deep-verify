# Core Pattern Library — Universal Impossibility Patterns
# LOAD: Always loaded by step-01-pattern-scan.md and step-02-targeted.md
# PURPOSE: Quick detection of artifacts that violate known theorems or contain definitional contradictions

---
library_metadata:
  id: "core"
  version: "1.0.0"
  last_updated: "2025-01-29"
  patterns_count: 15
  description: "Universal patterns applicable across all domains"
  update_protocol: "../pattern-update-protocol.yaml"
---
# DETECTION METHODS — HOW TO READ:
#
# Each pattern has a `detection_methods` field listing method procedure files.
# These reference files in: data/method-procedures/[FILENAME]
#
# Format: "NNN_Method_Name.md" where NNN is zero-padded method number
#
# To use:
#   1. Read the file: data/method-procedures/071_First_Principles_Analysis.md
#   2. Follow the procedure described to detect this pattern
#   3. Methods are listed in recommended order (most effective first)

---
definitional_contradictions:
  PFS_ESCROW:
    id: DC-001
    name: "PFS + Escrow Contradiction"
    signals:
      - "Perfect Forward Secrecy"
      - "key recovery mechanism"
      - "session key escrow"
      - "lawful intercept"
    why_impossible: |
      PFS means past sessions are unrecoverable even if long-term keys are compromised.
      Escrow/recovery means past sessions ARE recoverable.
      These are mutually exclusive by definition.
    detection_methods: ["071_First_Principles_Analysis.md", "154_Definitional_Contradiction_Detector.md"]
    severity: CRITICAL
    check: "Does artifact claim both forward secrecy AND key recovery?"

  GRADUAL_TERMINATION:
    id: DC-002
    name: "Gradual Typing + Guaranteed Termination"
    signals:
      - "gradual typing"
      - "dynamic types"
      - "optional types"
      - "guaranteed termination"
      - "always terminates"
    why_impossible: |
      Gradual typing allows runtime type coercion which enables arbitrary computation.
      Rice's theorem: non-trivial semantic properties are undecidable.
      Cannot guarantee termination for arbitrary programs with dynamic typing.
    theorem: "Rice's theorem"
    detection_methods: ["153_Theoretical_Impossibility_Check.md", "154_Definitional_Contradiction_Detector.md"]
    severity: CRITICAL
    validated: T21
    check: "Does artifact claim type flexibility AND termination guarantees?"

  DETERMINISTIC_ADAPTIVE:
    id: DC-003
    name: "Deterministic + Adaptive Conflict"
    signals:
      - "deterministic"
      - "reproducible"
      - "same input same output"
      - "learning"
      - "adaptive"
      - "self-improving"
    why_impossible: |
      Deterministic = same input -> same output always.
      Adaptive = output changes based on learning.
      These directly contradict unless scope is clearly separated.
    exception: "Valid if scope clearly separated (deterministic inference, adaptive training)"
    detection_methods: ["154_Definitional_Contradiction_Detector.md", "084_Coherence_Check.md"]
    severity: CRITICAL
    severity_if_scoped: IMPORTANT
    validated: T22
    check: "Does artifact claim both reproducibility AND learning without clear scope separation?"

  CONSISTENCY_AVAILABILITY:
    id: DC-004
    name: "CAP Theorem Violation"
    signals:
      - "strong consistency"
      - "linearizability"
      - "high availability"
      - "always available"
      - "partition tolerance"
      - "network partition"
    why_impossible: |
      CAP theorem: In presence of network partitions, must choose between
      consistency (all nodes see same data) and availability (all requests get response).
      Cannot have all three simultaneously.
    theorem: "CAP theorem (Brewer/Gilbert-Lynch)"
    detection_methods: ["153_Theoretical_Impossibility_Check.md"]
    severity: CRITICAL
    check: "Does artifact claim strong consistency + high availability + partition tolerance?"
---
theorem_violations:
  VCG_BALANCED:
    id: TV-001
    name: "VCG + Balanced Budget Impossibility"
    signals:
      - "VCG mechanism"
      - "Vickrey"
      - "strategy-proof"
      - "incentive compatible"
      - "balanced budget"
      - "no external subsidy"
      - "individual rationality"
    why_impossible: |
      Green-Laffont theorem: Cannot have VCG mechanism that is simultaneously
      strategy-proof, individually rational, efficient, AND budget-balanced.
      At least one must be sacrificed.
    theorem: "Green-Laffont impossibility"
    detection_methods: ["153_Theoretical_Impossibility_Check.md"]
    severity: CRITICAL
    validated: T19
    check: "Does artifact claim VCG + strategy-proofness + balanced budget + individual rationality?"

  ASYNC_CONSENSUS:
    id: TV-002
    name: "FLP Impossibility Violation"
    signals:
      - "asynchronous network"
      - "no timing assumptions"
      - "consensus"
      - "agreement"
      - "fault tolerance"
      - "f < N/2"
      - "guaranteed termination"
    why_impossible: |
      FLP theorem: In asynchronous network, consensus is impossible with even one faulty process
      if we require termination. Practical systems use timeouts (synchrony assumption) or
      probabilistic termination.
    theorem: "FLP impossibility"
    note: "f < N/3 is proven bound for async BFT; f < N/2 requires synchrony"
    detection_methods: ["153_Theoretical_Impossibility_Check.md", "071_First_Principles_Analysis.md"]
    severity: CRITICAL
    check: "Does artifact claim async + consensus + fault tolerance + guaranteed termination?"

  UNIVERSAL_TERMINATION:
    id: TV-003
    name: "Universal Termination Detection"
    signals:
      - "detects all infinite loops"
      - "guarantees termination"
      - "halting detection"
      - "proves termination for any program"
    why_impossible: |
      Halting problem: It is undecidable whether an arbitrary program terminates.
      No algorithm can correctly determine termination for ALL programs.
    theorem: "Halting problem (Turing)"
    detection_methods: ["153_Theoretical_Impossibility_Check.md", "087_Falsifiability_Check.md"]
    severity: CRITICAL
    validated: T18
    check: "Does artifact claim to detect termination for arbitrary programs?"

  UNIVERSAL_BUG_DETECTION:
    id: TV-004
    name: "Universal Bug/Risk Detection"
    signals:
      - "100% recall"
      - "finds all bugs"
      - "detects all risks"
      - "complete coverage"
      - "no false negatives"
    why_impossible: |
      Rice's theorem: Non-trivial semantic properties of programs are undecidable.
      Open-ended problem spaces cannot have complete detection.
      "All bugs" or "all risks" is an unbounded set.
    theorem: "Halting problem variant / Rice's theorem"
    detection_methods: ["153_Theoretical_Impossibility_Check.md", "071_First_Principles_Analysis.md"]
    severity: CRITICAL
    validated: T23
    check: "Does artifact claim 100% detection for open-ended problem space?"

  ARROW_VOTING:
    id: TV-005
    name: "Arrow's Impossibility Violation"
    signals:
      - "voting system"
      - "social choice"
      - "fair aggregation"
      - "unrestricted domain"
      - "non-dictatorship"
      - "Pareto efficiency"
      - "independence of irrelevant alternatives"
    why_impossible: |
      Arrow's theorem: No voting system can satisfy all of:
      - Unrestricted domain
      - Non-dictatorship
      - Pareto efficiency
      - Independence of irrelevant alternatives
    theorem: "Arrow's impossibility theorem"
    detection_methods: ["153_Theoretical_Impossibility_Check.md"]
    severity: CRITICAL
    check: "Does artifact claim voting system satisfying all four Arrow criteria?"
---
statistical_impossibilities:
  ACCURACY_WITHOUT_N:
    id: SI-001
    name: "High Accuracy Without Sample Size"
    signals:
      - "99% accuracy"
      - "99.9% accuracy"
      - "near-perfect accuracy"
      - percentage claims without N
    why_problematic: |
      High accuracy claims require sufficient sample size to be meaningful.
      N x prevalence x claimed_accuracy must yield statistically significant validation.
      Example: 99.9% on 10K diseases with 50M records = ~5K/disease avg; rare diseases have <100.
    detection_methods: ["153_Theoretical_Impossibility_Check.md"]
    severity: CRITICAL
    validated: "T18, T22"
    check: "Does artifact claim high accuracy without specifying sample size or prevalence?"

  UNVERIFIABLE_OPTIMUM:
    id: SI-003
    name: "Unverifiable Global Optimum"
    signals:
      - "finds global optimum"
      - "optimal solution"
      - ">99% probability of optimal"
      - "guaranteed best"
      - NP-hard problem reference
    why_problematic: |
      For NP-hard problems, verifying global optimality requires exhaustive search.
      Claims of finding "the" optimum without proof methodology are unfalsifiable.
      Heuristics can find "good" solutions but cannot prove optimality.
    detection_methods: ["153_Theoretical_Impossibility_Check.md", "085_Grounding_Check.md"]
    severity: CRITICAL
    validated: "T18, T20"
    check: "Does artifact claim global optimum for NP-hard problem without verification method?"
---
ungrounded_core_concepts:
  UNDEFINED_KEY_TERM:
    id: UG-001
    name: "Undefined Central Concept"
    signals:
      - key term used repeatedly without definition
      - core value proposition lacks operational definition
      - '"material risk" / "significant" / "appropriate" without criteria'
    why_problematic: |
      If the central concept is undefined, the primary value proposition cannot be verified.
      Vague terms enable goal-post moving.
      Operationalization is required for measurable claims.
    detection_methods: ["100_Vocabulary_Consistency.md", "085_Grounding_Check.md"]
    severity: IMPORTANT
    severity_if_central: CRITICAL
    validated: T23
    check: "Is there a key term central to value proposition that lacks operational definition?"

  CIRCULAR_DEFINITION:
    id: UG-002
    name: "Circular Definition"
    signals:
      - X defined in terms of Y
      - Y defined in terms of X
      - self-referential definition
    why_problematic: |
      Circular definitions provide no actual meaning.
      Cannot extract operational criteria from circularity.
    detection_methods: ["100_Vocabulary_Consistency.md", "116_Strange_Loop_Detection.md"]
    severity: IMPORTANT
    check: "Are key terms defined circularly?"

  SCOPE_CREEP_DEFINITION:
    id: UG-003
    name: "Scope Creep Definition"
    signals:
      - same term used differently in different sections
      - meaning shifts throughout document
    why_problematic: |
      If term means different things in different places, which meaning applies?
      Enables equivocation fallacy.
    detection_methods: ["100_Vocabulary_Consistency.md", "084_Coherence_Check.md"]
    severity: IMPORTANT
    check: "Does the same term have different meanings in different sections?"
---
# USAGE SUMMARY:
#
# 1. For each finding in Phase 1, check pattern_id against this library
# 2. Pattern match -> +1 bonus to evidence score (max +1 per finding)
# 3. No match but S >= 6 -> proceed to Phase 2 for confirmation
# 4. Use 'check' questions to verify pattern applicability
# 5. Reference 'detection_methods' for which methods best find this pattern
