# Feasibility Scoring System — 10-Dimension Assessment
# LOAD: step-02-assess.md
# PURPOSE: Consistent scoring across all feasibility dimensions

---
# LOADING INSTRUCTIONS:
# 1. Load this file at the START of ASSESS phase
# 2. Apply dimension_scale for each of 10 dimensions
# 3. Identify binding constraint (min score)
# 4. Assign confidence level to each score

---
dimension_scale:
  5:
    label: "Proven"
    description: "Demonstrated, precedented, no significant challenges"
    indicators:
      - "Direct precedent exists with similar context"
      - "Team has done this before successfully"
      - "Technology is mature (TRL 8-9)"
      - "No significant unknowns"

  4:
    label: "Likely"
    description: "Strong evidence of feasibility, minor concerns"
    indicators:
      - "Analogous precedent exists"
      - "Team has related experience"
      - "Technology is proven but new to team"
      - "Minor gaps, closable with reasonable effort"

  3:
    label: "Possible"
    description: "Feasible but significant challenges or uncertainties"
    indicators:
      - "Partial precedent exists"
      - "Team has some relevant experience"
      - "Significant learning curve or gaps"
      - "Requires validation before confidence"

  2:
    label: "Doubtful"
    description: "Major challenges, may require fundamental changes"
    indicators:
      - "Limited or no precedent"
      - "Team lacks key experience"
      - "Multiple significant unknowns"
      - "Likely requires scope/approach change"

  1:
    label: "Infeasible"
    description: "Cannot be done under current constraints"
    indicators:
      - "Violates known limits (H4-H5 constraint)"
      - "Critical capability missing with no path to acquire"
      - "Timeline/budget impossibly short"
      - "Fundamental contradiction unresolved"

---
dimensions:
  technical:
    number: 201
    name: "Technical Feasibility"
    question: "Does the required technology exist, work, and scale?"
    sub_factors:
      - name: "Technology Readiness Level (TRL)"
        anchors:
          5: "TRL 8-9 — Production-proven"
          4: "TRL 6-7 — Prototype/demo proven"
          3: "TRL 4-5 — Lab validated"
          2: "TRL 2-3 — Concept only"
          1: "TRL 1 or unknown"
      - name: "Scale validation"
        anchors:
          5: "Tested at production scale"
          3: "Tested at representative scale"
          1: "Only demo/POC scale"
      - name: "Integration maturity"
        anchors:
          5: "Standard integration patterns"
          3: "Custom integration needed"
          1: "No known integration path"

  resource:
    number: 202
    name: "Resource Feasibility"
    question: "Do we have people, budget, infrastructure, tools?"
    sub_factors:
      - name: "People/Skills"
      - name: "Budget"
      - name: "Infrastructure"
      - name: "Tools/Licenses"
      - name: "Time availability"
    brooks_law_note: |
      Adding people to late project makes it later.
      Communication overhead = n(n-1)/2 for n people.

  knowledge:
    number: 203
    name: "Knowledge Feasibility"
    question: "Does the team know HOW to do this?"
    sub_factors:
      - name: "Domain knowledge"
      - name: "Technical knowledge"
      - name: "Architectural knowledge"
      - name: "Procedural knowledge"
      - name: "Tacit knowledge"
    dunning_kruger_note: |
      Low expertise + High confidence = DANGER ZONE.
      Seek external validation for these areas.

  organizational:
    number: 204
    name: "Organizational Feasibility"
    question: "Can the organization execute this?"
    sub_factors:
      - name: "Decision authority"
      - name: "Cross-team coordination"
      - name: "Conway alignment"
      - name: "Culture fit"
      - name: "Change capacity"
      - name: "Stakeholder alignment"
      - name: "Political feasibility"

  temporal:
    number: 205
    name: "Temporal Feasibility"
    question: "Can we do this in the time available?"
    sub_factors:
      - name: "Critical path vs deadline"
      - name: "Parallelism limits"
      - name: "Non-work time (meetings, holidays)"
      - name: "Waiting time (approvals, provisioning)"
      - name: "Integration time (30-50% typical)"
    calendar_traps:
      - "Effort ≠ Duration"
      - "Linear parallelism assumption"
      - "Invisible waiting time"
      - "Integration time ignored"

  compositional:
    number: 206
    name: "Compositional Feasibility"
    question: "Do the parts work together as a system?"
    sub_factors:
      - name: "Interface definitions"
      - name: "Integration precedent"
      - name: "Error handling coverage"
      - name: "State management clarity"
      - name: "Version coupling"
    integration_effort_guide:
      well_defined: "15-20%"
      partial: "30-40%"
      undefined: "50-70%"

  economic:
    number: 207
    name: "Economic Feasibility"
    question: "Is it worth doing? (Costs vs benefits)"
    sub_factors:
      - name: "Total cost (dev + infra + ops)"
      - name: "Total benefit (revenue, savings, risk reduction)"
      - name: "ROI"
      - name: "Payback period"
      - name: "Sensitivity to cost changes"
      - name: "Strategic value"

  regulatory:
    number: 208
    name: "Regulatory Feasibility"
    question: "Is it legally permitted?"
    sub_factors:
      - name: "Jurisdiction clarity"
      - name: "Requirement mapping"
      - name: "Compliance path"
      - name: "Regulatory stability"
    note: "Prohibited activity = H5 constraint"

  scale:
    number: 209
    name: "Scale Feasibility"
    question: "Does it work at production scale?"
    sub_factors:
      - name: "Data volume gap"
      - name: "Concurrent users gap"
      - name: "Uptime requirement shift"
      - name: "Error handling completeness"
      - name: "Security maturity"
    poc_to_prod_multiplier:
      similar_scale_done: "3×"
      new_scale_known_patterns: "5×"
      new_scale_new_patterns: "10×"

  cognitive:
    number: 210
    name: "Cognitive Feasibility"
    question: "Can the team understand what they're building?"
    sub_factors:
      - name: "Concept count (>7-9 = risk)"
      - name: "Concept coupling"
      - name: "Abstraction quality"
      - name: "Onboarding time (>3 months = risk)"

  dependency:
    number: 211
    name: "Dependency Feasibility"
    question: "Are external dependencies available and reliable?"
    sub_factors:
      - name: "Availability"
      - name: "Reliability (SLA)"
      - name: "Affordability at scale"
      - name: "Stability (deprecation risk)"
      - name: "Timeliness"

---
confidence_levels:
  high:
    symbol: "H"
    description: "Based on empirical evidence"
    sources:
      - "Validated probes/spikes"
      - "Reference class data"
      - "Direct measurements"
      - "Team's direct experience with same tech/domain"
    reliability: "Strong — trust the score"

  medium:
    symbol: "M"
    description: "Based on expert judgment (calibrated) and analogies"
    sources:
      - "Calibrated expert estimates"
      - "Analogies with verified structural similarity"
      - "Industry patterns/benchmarks"
    reliability: "Moderate — validate key assumptions"

  low:
    symbol: "L"
    description: "Based on team gut feeling and planning"
    sources:
      - "Internal planning estimates"
      - "Intuition/experience"
      - "Limited information"
    reliability: "Weak — requires validation before trusting"

---
binding_constraint:
  formula: "min(all dimension scores)"
  rationale: |
    A project feasible on 9/10 dimensions but infeasible on 1
    is INFEASIBLE overall. Like a chain — strength determined by
    weakest link. (Goldratt's Theory of Constraints)

  do_not:
    - "Average the scores"
    - "Weight by 'importance'"
    - "Ignore low-scoring dimensions"

  do:
    - "Identify binding constraint (lowest score)"
    - "Focus improvement efforts on binding constraint"
    - "Overall feasibility = min(all dimensions)"

---
# USAGE SUMMARY:
#
# 1. Score each of 10 dimensions using anchors (1-5)
# 2. Assign confidence level (H/M/L) to each score
# 3. Calculate binding constraint: min(all scores)
# 4. Overall feasibility = binding constraint score
# 5. Note: Same score + different confidence = different decision
